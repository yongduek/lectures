
# Training An Image Classifier for CIFAR10 Image Data

This part is from [Training A Classifier](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py)

## What About Data?

Generally, when you have to deal with image, text, audio or video data, you can use standard python packages that load data into a numpy array. Then you can convert this array into a torch.*Tensor.

- For images, packages such as Pillow, OpenCV are useful
- For audio, packages such as scipy and librosa
- For text, either raw Python or Cython based loading, or NLTK and SpaCy are useful

Specifically for vision, we have created a package called `torchvision`, that has data loaders for common datasets such as Imagenet, CIFAR10, MNIST, etc. and data transformers for images, viz., `torchvision.datasets` and `torch.utils.data.DataLoader`.

This provides a huge convenience and avoids writing boilerplate code.

## CIFAR-10 Dataset

For this tutorial, we will use the CIFAR10 dataset. It has the classes: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’. The images in CIFAR-10 are of size 3x32x32, i.e. 3-channel color images of 32x32 pixels in size.

```{r, echo=FALSE, fig.align='center', fig.cap='Sample images of CIFAR-10 Dataset'}
knitr::include_graphics('data/cifar10.png')
```

The detail on the original source of CIFAR-10 dataset is provided in [The CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).

- The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. 

- The dataset is divided into five training batches and one test batch, each with 10000 images. The test batch contains exactly 1000 randomly-selected images from each class. The training batches contain the remaining images in random order, but some training batches may contain more images from one class than another. Between them, the training batches contain exactly 5000 images from each class. 

- The classes are completely mutually exclusive. There is no overlap between automobiles and trucks. "Automobile" includes sedans, SUVs, things of that sort. "Truck" includes only big trucks. Neither includes pickup trucks.

- The best test accuracy was 96.53% (Fractional Max-Pooling by Benjamin Graham, 2015). The history can be found in [Who is the best in CIFAR-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).


## Chapter Plan

We will do the following steps in order:

1. Load and normalize the CIFAR-10 training and test datasets using `torchvision`
1. Define a Convolution Neural Network
1. Define a loss function
1. Train the network on the training data
1. Test the network on the test data


## Load and normalizing the CIFAR-10 dataset for training and test

Using torchvision, it’s extremely easy to load CIFAR-10.

```{python}
import torch
import torchvision
import torchvision.transforms as transforms
```

The output of torchvision datasets are `PILImage` images of range [0, 1]. We transform them to Tensors of normalized range [-1, 1].

```{python}
transform = transforms.Compose(
    [transforms.ToTensor(),
     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

trainset = torchvision.datasets.CIFAR10(root='./data', train=True,
                                        download=True, transform=transform)
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True)

testset = torchvision.datasets.CIFAR10(root='./data', train=False,
                                       download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                         shuffle=False)

classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
```

* You have a look at the directory named `./data`. It will have several files including `batches.meta` and `test_batch`:
```{python}
import os
print(os.listdir('./data'))
print (os.listdir('./data/cifar-10-batches-py'))
```

Let us show some of the training images, for fun.
```{python}
import matplotlib.pyplot as plt
import numpy as np

# get some random training images
dataiter = iter(trainloader)
images, labels = dataiter.next()
print ('> output of dataiter.next():\n', 
    'images: ', type(images), images.shape, '\n', 'labels: ', type(labels), 'labels={}'.format(labels))

# show images
def imshow (images, labels):
    fig, axes = plt.subplots(1,4)
    for i, ax in enumerate(axes):
        npimg = images[i].numpy().transpose((1,2,0)) / 2 + 0.5
        ax.imshow(npimg)
        ax.set_title (classes[labels[i]])
        #print ('type(img) = ', type(images[i]), images[i].shape, '-->', npimg.shape)
    
    plt.show()
#
imshow (images, labels) ## display the minibatch
```

* The mini-batch of images returned by `dataiter.next()` has 4 images.
* Their format is `(channel, width, height)` which is required for `pytorch` operations. However, `plt` expects a numpy array of `(width, height, channel)`. This is why we need `transpose((1,2,0))`.
* Image scaling is required to scale the pixel values to [0,1] range.
* The image's class label is printed on each of the image.




## Define a Convolution Neural Network

```{python}
import torch.nn as nn
import torch.nn.functional as F

class myNet(nn.Module):
    def __init__(self):
        super(myNet, self).__init__()
        self.conv1 = nn.Conv2d(3, 6, 5)
        self.relu1 = nn.ReLU()
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(6, 16, 5)
        self.relu2 = nn.ReLU()
        self.fc1 = nn.Linear(16 * 5 * 5, 120)
        self.fc2 = nn.Linear(120, 84)
        self.fc3 = nn.Linear(84, 10)

    def forward(self, x):
        x = self.pool(self.relu1(self.conv1(x)))
        x = self.pool(self.relu2(self.conv2(x)))
        x = x.view(-1, 16 * 5 * 5)
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x
#

net = myNet()

print (net)
```

What is this netowrk? What are the modules used in `myNet`? They will be explained at the very late sections. 
For now, let's just remember that 

- the input is a mini-batch of images of size `4x3x32x32` and 
- the output is a vector of 10 integer numbers, each of which indicates a possibility of the image being the class label.

* You may want to put `softmax` at the end of the network. Then you will have 10 probabilities. With python, we don't have to. Below, we use `torch.nn.CrossEntropyLoss` as the loss function, and it combines `nn.LogSoftmax` and `nn.NLLLoss` in one single class. 
* See [`torch.nn.CrossEntropyLoss`](https://pytorch.org/docs/stable/nn.html#crossentropyloss), which says: 
    - It is useful when training a classification problem with C classes. 
    - The **input** is expected to contain scores for each class.
    - The **input** has to be a Tensor of size `(minibatch,C)`
    - This criterion expects a class index `(0 to C-1)` (an integer number) as the target for each value of a 1D tensor of size `minibatch`.


Let's have a look at what the output of the model looks like.
```{python}
with torch.no_grad():
    for data in trainloader:
        images, labels = data
        outputs = net (images)
        print (outputs)
        break
```
As we expected, the `outputs` is the tensor of size `4x10`. That is, 4 outputs, each of which is of dimension 10. Then the loss function `torch.nn.CrossEntropyLoss` will take care of the rest for learning the multi-label classification problem.


## Define a loss function

```{python}
import torch.optim as optim

criterion = nn.CrossEntropyLoss()
optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)
```

* Here we use `nn.CrossEntropyLoss()`. What is this?


## Train the network on the training data

Let's define a function for the learing loop. Then each time we call this function, the network will learn through the loss function.

```{python}
def learning_loop (nepochs):
    for epoch in range(nepochs):  # loop over the dataset multiple times
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            # get the inputs
            inputs, labels = data
    
            # zero the parameter gradients
            optimizer.zero_grad()
    
            # forward + backward + optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
    
            # print statistics
            running_loss += loss.item()
            if i % 2000 == 1999:    # print every 2000 mini-batches
                print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 2000))
                running_loss = 0.0
    
    print('Finished Training')
#
```

Now let's  try 2 epochs of learning, and see how long it takes.
```{python}
import time
start_time = time.time()

learning_loop (2) # 

print (' Elapsed time: %s seconds' % (time.time() - start_time))
```






## Test the network on the test data

We have trained the network for 2 passes over the training dataset. But we need to check if the network has learnt anything at all.

We will check this by predicting the class label that the neural network outputs, and checking it against the ground-truth. If the prediction is correct, we add the sample to the list of correct predictions.

Okay, first step. Let us display an image from the test set to get familiar.

```{python}
dataiter = iter(testloader)
images, labels = dataiter.next()

# print images
imshow(images, labels)
```
Okay, now let us see what the neural network thinks these images above are:
```{python}
outputs = net(images)
```
The outputs are energies for the 10 classes. The higher the energy for a class, the more the network thinks that the image is of the particular class. So, let’s get the index of the highest energy:

```{python}
_, predicted = torch.max(outputs, 1)

print(' Ground Truth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)),
    '\n', 'Predicted   : ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))
```

Q. What do you think of the result?


### test for the whole dataset
Let us look at how the network performs on the whole dataset.

```{python}
correct = 0
total = 0
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs.data, 1)
        total += labels.size(0)
        correct += (predicted == labels).sum().item()

print('Accuracy of the network on the 10000 test images: %d %%' % (
    100 * correct / total))
````

Q. What is the accuracy of the network on the 10000 test images?

In my computer it showed 51%. This was way better than chance, which was 10% accuracy (randomly picking a class out of 10 classes). It seemed like the network learnt something.

Hmmm, what are the classes that performed well, and the classes that did not perform well:

```{python}
class_correct = list(0. for i in range(10))
class_total = list(0. for i in range(10))
with torch.no_grad():
    for data in testloader:
        images, labels = data
        outputs = net(images)
        _, predicted = torch.max(outputs, 1)
        c = (predicted == labels).squeeze()
        for i in range(4):
            label = labels[i]
            class_correct[label] += c[i].item()
            class_total[label] += 1


for i in range(10):
    print('Accuracy of %5s : %2d %%' % (
        classes[i], 100 * class_correct[i] / class_total[i]))
```

Some class have better accuracy than others. Interesting.



## TRAINING ON GPU
You can use GPU (Nvidia cuda) for neural network learning.

Let’s first define our device as the first visible cuda device if we have CUDA available:

```{python}
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print (device)
```

The rest of this section assumes that device is a CUDA device.

Then these methods will recursively go over all modules and convert their parameters and buffers to CUDA tensors:

```{python}
net.to(device)
```

Remember that you will have to send the inputs and targets at every step to the GPU too:

```
  inputs, labels = inputs.to(device), labels.to(device)
```

```
def learning_loop_gpu (nepochs):
    for epoch in range(nepochs):  # loop over the dataset multiple times
        running_loss = 0.0
        for i, data in enumerate(trainloader, 0):
            # get the inputs
            inputs, labels = data
            inputs.to(device)
            labels.to(device)

            # zero the parameter gradients
            optimizer.zero_grad()
    
            # forward + backward + optimize
            outputs = net(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
    
            # print statistics
            running_loss += loss.item()
            if i % 2000 == 1999:    # print every 2000 mini-batches
                print('[%d, %5d] loss: %.3f' %
                      (epoch + 1, i + 1, running_loss / 2000))
                running_loss = 0.0
    
    print('Finished Training')
#
```

```
import time
start_time = time.time()

learning_loop_gpu (2) # 

print (' Elapsed time: %s seconds' % (time.time() - start_time))
```

Why dont I notice MASSIVE speedup compared to CPU? Because your network is realllly small.

Exercise: Try increasing the width of your network (argument 2 of the first nn.Conv2d, and argument 1 of the second nn.Conv2d – they need to be the same number), see what kind of speedup you get.

Goals achieved:

Understanding PyTorch’s Tensor library and neural networks at a high level.
Train a small neural network to classify images


## `torch.nn` modules used in `myNet`

### `Conv2d`: a convolutional Neural Netowrk for 2d image data
### `ReLU`: an activation function
### `MaxPool2d`
### `Linear`


## Conclusion

https://github.com/yunjey/pytorch-tutorial

EOC
