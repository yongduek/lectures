
# Datasets

Data collection over the internet. Easy to find in `Kaggle`, `torchvision`, `torchtext`.

Needed is a dataset in 한글.

## Image Data

## Text Data

## Others

## Open Images Dataset 

Dataset: [Google Open Images](https://storage.googleapis.com/openimages/web/index.html)

```{r open-images-dataset-categories, echo=FALSE, fig.align='center', fig.cap='Categories of Google Open Images dataset (600 labels)'}
knitr::include_graphics('figures/open-images-dataset-categories.png')
```

An interactive annotated version of the chart is [here](https://alpha.quiltdata.com/b/quilt-example/tree/quilt/open_images/).

```{r open-images-topmost20, echo=FALSE, fig.align='center', fig.cap='Top most 20 of the Categories of Google Open Images dataset'}
knitr::include_graphics('figures/open-images-topmost20.png')
```

### How to classfy Hamburger & Sandwich Using Open Image

Purpose:

  1. Download two sets of images into a folder separted by their category names.
  1. Use transfer learning for the classification

Article source: [How to classify photos in 600 classes using Nine million Open Images](https://medium.freecodecamp.org/how-to-classify-photos-in-600-classes-using-nine-million-open-images-65847da1a319)

- Keras code is provided.

If you’re looking build an image classifier but need training data, look no further than Google Open Images.

This massive image dataset contains over 30 million images and 15 million bounding boxes. That’s 18 terabytes of image data!

Plus, Open Images is much more open and accessible than certain other image datasets at this scale. For example, ImageNet has restrictive licensing.

However, it’s not easy for developers on single machines to sift through that much data.You need to download and process multiple metadata files, and roll their own storage space (or apply for access to a Google Cloud bucket).

On the other hand, there aren’t many custom image training sets in the wild, because frankly they’re a pain to create and share.

In this article, we’ll build and distribute a simple end-to-end machine learning pipeline using Open Images.

We’ll see how to create your own dataset around any of the 600 labels included in the Open Images bounding box data.

We’ll show off our handiwork by building “open sandwiches”. These are simple, reproducible image classifiers built to answer an age-old question: is a hamburger a sandwich?

Want to see the code? You can follow along in the repository on [GitHub](https://github.com/quiltdata/open-images). 

#### Downloading the data

We need to download the relevant data before we can do anything with it.

This is the core challenge when working with Google Open Images (or any external dataset really). There is no easy way to download a subset of the data. We need to write a script that does so for us.

I’ve written a Python script that searches the metadata in the Open Images data set for keywords that you specify. It finds the original URLs of the corresponding images (on Flickr), then downloads them to disk.

It’s a testament to the power of Python that you can do all of this in just 50 lines of code:
```{python, eval=FALSE, code=readLines('open-images/src/openimager/openimager.py')}
```




<!- EOF ->