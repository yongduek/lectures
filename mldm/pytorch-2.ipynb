{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with tensor from torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = 2 * x + 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch as th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.9358,  0.1665,  0.6279,  0.3196,  0.0511,  0.9084,  0.3410,\n",
      "         0.9417]) torch.float32 torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "ndata = 8\n",
    "x = th.rand (ndata, requires_grad=False)\n",
    "print (x, x.dtype, x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare Variables for gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 2.]) tensor([ 3.]) torch.Size([1]) torch.float32\n",
      "yTrue=  tensor([ 4.8716,  3.3331,  4.2558,  3.6392,  3.1022,  4.8167,  3.6820,\n",
      "         4.8835])\n",
      "yTrue in numpy object =  [ 4.87159157  3.33306646  4.25578642  3.63919449  3.10224295  4.81673002\n",
      "  3.68203402  4.88348341]\n"
     ]
    }
   ],
   "source": [
    "wTrue = th.tensor([2.], dtype=th.float32, requires_grad=True)\n",
    "bTrue = th.tensor([3.], requires_grad=True)\n",
    "print (wTrue, bTrue, bTrue.shape, bTrue.dtype)\n",
    "\n",
    "yTrue = wTrue * x  +  bTrue               # all elementwise operation\n",
    "print ('yTrue= ', yTrue)\n",
    "print ('yTrue in numpy object = ', yTrue.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x116f1e5c0>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot (x.data.numpy(), yTrue.data.numpy(), 'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = th.tensor( [-3.], requires_grad=True)\n",
    "b = th.tensor ([-20.], requires_grad=True)\n",
    "\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-229.7425]) tensor([-229.7425])\n",
      "0  loss =  tensor(5299.9438) 5299.94384765625\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-0f90cdd8e1f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# compute gradients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time, but the buffers have already been freed. Specify retain_graph=True when calling backward the first time."
     ]
    }
   ],
   "source": [
    "nIter = 5\n",
    "\n",
    "for t in range (nIter):\n",
    "    # forward pass\n",
    "    ypred = x * w + b\n",
    "    \n",
    "    # compute loss\n",
    "    err = ypred - yTrue\n",
    "    loss = err.pow(2).sum() #th.sum( err * err )\n",
    "    \n",
    "    # compute gradients\n",
    "    loss.backward()\n",
    "    \n",
    "    with th.no_grad():\n",
    "        print (w.grad, w.grad.data)\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    # \n",
    "    print (t, ' loss = ', loss, loss.item())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
