
# LSTM & Sequence Models

- check out [sequence models and LSTM Networks](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py)

## LSTM in `pytorch.nn`

- [`torch.nn.LSTM(*args, **kwargs)`](https://pytorch.org/docs/stable/nn.html#lstm)
    - `torch.nn.LSTM(input_size, output_size, num_layers, batch_first=False, bidirectional=False)`
        - If `bach_first=False`, `input.shape = [time, batch, feature]`, else `input.shape = [batch, time, feature]`
    - Inputs: `input, (h, c)`, if `(h,c)` is not provided, both default to zero.
    - Outputs: `output, (h, c)`

```{python lstmIntro}
import torch
import torch.nn as nn
inputDim = 3
outputDim = 4
lstm = nn.LSTM (inputDim, outputDim) # input:3, output:4

timeDim = 5 # sequence length
batchDim = 2 # mini batch
featDim = inputDim
input = torch.randn(timeDim, batchDim, featDim)

output, (hn, cn) = lstm (input) # initial (h,c)=(0,0)

print ('output(#time,#batch,#out): {}\nh(#out): {}\nc(#out):{}'.format(output.shape, hn.shape, cn.shape))
```

* Why does `time` dimension come first? It is a deault convention of PyTorch.
* We can have `batch` first as shown in the following.

```{python lstmIntro2}
import torch
import torch.nn as nn
inputDim = 3
outputDim = 4
lstm = nn.LSTM (inputDim, outputDim, batch_first=True) # input:3, output:4

timeDim = 5 # sequence length
batchDim = 2 # mini batch
featDim = inputDim
input = torch.randn(batchDim, timeDim, featDim)

output, (hn, cn) = lstm (input) # initial (h,c)=(0,0)

print ('output(#batch,#time,#out): {}\nh(#out): {}\nc(#out):{}'.format(output.shape, hn.shape, cn.shape))
```

* The dimension of `h` and `c` did not change regardless of the `batch_first` option.


## Playing with LSTM

```{python lstm1}
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
torch.manual_seed(1)

inputDim = 3 # feature dimension
outputDim = 4
timeDim = 5 # sequence length

# lstm, batch_first=False
lstm = nn.LSTM(inputDim, outputDim)  # Input dim is 3, output dim is 3

inputs = [torch.randn(1, inputDim) for _ in range(timeDim)]  # make a sequence of length 5
print ('inputs len: ', len(inputs))
print ('inputs[0].shape: ', inputs[0].shape, '\n',
       'resized by inputs[0].view(1,1,-1):', inputs[0].view(1,1,-1).shape)
# view(1,1,-1): only one of the axis value can be -1
# reshape() returns a view() if the shapes are compatible, and copies otherwise.

# initialize the hidden state. It could be random or 0 [time, batch, output]
hidden = (torch.zeros(1, 1, outputDim), torch.zeros(1, 1, outputDim))
          
for inp in inputs: # step through time
    # Step through the sequence one element (one batch) at a time.
    # after each step, hidden contains the hidden state.
    out, hidden = lstm(inp.view(1, 1, -1), hidden)

print ('out.shape: ', out.shape, '\n', 'hidden: ', hidden[0].shape, hidden[1].shape)

# Alternatively, we can do the entire sequence all at once.
# The first value returned by LSTM is all of the hidden states throughout
# the sequence. 
# The second is just the most recent hidden state
# (compare the last slice of "out" with "hidden" below, they are the same)

inputs = torch.cat(inputs).view(len(inputs), 1, -1) # [time, batch, input_feature_dim]
print ('inputs.shape: ', inputs.shape)
hidden = (torch.randn(1, 1, outputDim), torch.randn(1, 1, outputDim))  # clean out hidden state

out, hidden = lstm(inputs, hidden)

print(out.shape, '\n', out.data)
print(hidden[0].data, hidden[1].data)
```


## `batch_first=True`

```{python lstm2}
torch.manual_seed(1)

inputDim = 3 # feature dimension
outputDim = 4
timeDim = 5 # sequence length

lstm = nn.LSTM(inputDim, outputDim, batch_first=True)  # Input dim is 3, output dim is 3

inputs = [torch.randn(1, inputDim) for _ in range(timeDim)]  # make a sequence of length 5
print ('inputs len: ', len(inputs))
print ('inputs[0].shape: ', inputs[0].shape, '\n',
       'resized by inputs[0].view(1,1,-1):', inputs[0].view(1,1,-1).shape)

# initialize the hidden state.
hidden = (torch.zeros(1, 1, outputDim), torch.zeros(1, 1, outputDim))
          
for inp in inputs: # step through time
    # Step through the sequence one element (one batch) at a time.
    # after each step, hidden contains the hidden state.
    out, hidden = lstm(inp.view(1, 1, -1), hidden)

print ('out.shape: ', out.shape, '\n', 'hidden: ', hidden[0].shape, hidden[1].shape)

inputs = torch.cat(inputs).view(1, len(inputs), -1) # [batch, time, input_feature_dim]
print ('inputs.shape: ', inputs.shape)
hidden = (torch.randn(1, 1, outputDim), torch.randn(1, 1, outputDim))  # clean out hidden state

out, hidden = lstm(inputs, hidden)

print(out.shape, '\n', out.data)
print(hidden[0].shape, '\n', hidden[0].data, hidden[1].data)
```


## LSTM for POS Tagging (Part-of-Speech)

```{python lstmPOSTag, code=readLines('python/lstm_pos_tagging.py')}
```

Q. try the option: batch_first=True

Q. Implement character level seq-seq learning. You might need two special words {SOS, EOS}.

EOF